{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1uyg3RQyCMd2obkr5GXD8j_iJRyqToxLq",
      "authorship_tag": "ABX9TyMB4+MOl9mYG0KmvNxuOCqm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhinayy27/NLP-Project/blob/main/main_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30Lf35mNy51k",
        "outputId": "3a1e2ee6-3788-446c-c14a-5f247dffbe96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "path ='/content/drive/MyDrive/ML/Blackcopper Test/Input.xlsx'\n",
        "input_df = pd.read_excel(path)\n",
        "\n",
        "# Function to clean extracted text\n",
        "def clean_extracted_text(text):\n",
        "    patterns_to_remove = [\n",
        "        r\"Firm Name:.*\",                # Remove firm details\n",
        "        r\"Email:.*\",                    # Remove email addresses\n",
        "        r\"Skype:.*\",                    # Remove Skype details\n",
        "        r\"WhatsApp:.*\",                 # Remove WhatsApp details\n",
        "        r\"We provide.*\",                # Remove boilerplate about services\n",
        "        r\"Â©.*All Right Reserved.*\",     # Remove legal copyright information\n",
        "        r\"Summarized:.*\",               # Remove summarization text\n",
        "        r\"AI and ML-Based YouTube Analytics.*\"  # Remove irrelevant repeated content\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns_to_remove:\n",
        "        text = re.sub(pattern, '', text, flags=re.DOTALL)\n",
        "\n",
        "    # Further cleaning: remove multiple newlines or excessive spaces\n",
        "    text = re.sub(r'\\n+', '\\n', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Function to extract content from the <div> with class \"td-post-content tagdiv-type\"\n",
        "def extract_text(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Target the specific div container by its class\n",
        "        main_content = soup.find('div', {'class': 'td-post-content tagdiv-type'})\n",
        "\n",
        "        if main_content:\n",
        "            # Extract title from <h1> tag\n",
        "            title = soup.find('h1').get_text().strip() if soup.find('h1') else 'No title'\n",
        "\n",
        "            # Extract paragraphs, ordered lists, list items, and other heading tags inside the main content\n",
        "            content_parts = []\n",
        "\n",
        "            # Extract paragraphs (<p>), ordered lists (<ol> and <li>), and headers (<h2>, <h3>, etc.)\n",
        "            for tag in main_content.find_all(['p', 'ol', 'li', 'h1', 'h2', 'h3', 'h4']):\n",
        "                content_parts.append(tag.get_text().strip())\n",
        "\n",
        "            # Join all parts together\n",
        "            article_text = '\\n'.join(content_parts)\n",
        "\n",
        "            cleaned_text = clean_extracted_text(article_text)\n",
        "            return title, cleaned_text\n",
        "        else:\n",
        "            print(f\"Main content not found for {url}\")\n",
        "            return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to extract from {url}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Output folder to store the files\n",
        "output_folder = '/content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Iterate through all URLs and save extracted text into a file\n",
        "for index, row in input_df.iterrows():\n",
        "    url_id = row['URL_ID']\n",
        "    url = row['URL']\n",
        "\n",
        "    title, text = extract_text(url)\n",
        "\n",
        "    if title and text:\n",
        "      try:\n",
        "        # Save the text to a file with URL_ID as the file name in the output folder\n",
        "        file_path = os.path.join(output_folder, f'{url_id}.txt')\n",
        "        with open(file_path, 'w', encoding='utf-8') as file:\n",
        "            file.write(f\"Title: {title}\\n\\n{text}\")\n",
        "        print(f\"Successfully saved: {file_path}\")\n",
        "      except Exception as e:\n",
        "            print(f\"Error writing file {url_id}: {e}\")\n",
        "    else:\n",
        "        print(f\"Failed to extract content for URL_ID {url_id}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hS_22Vbjy7fz",
        "outputId": "c13332ac-6e65-4146-89ac-e37fbbe4079a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2011.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2012.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2013.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2014.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2015.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2016.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2017.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2018.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2019.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2020.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2021.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2022.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2023.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2024.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2025.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2026.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2027.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2028.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2029.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2030.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2031.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2032.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2033.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2034.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2035.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2036.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2037.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2038.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2039.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2040.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2041.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2042.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2043.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2044.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2045.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2046.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2047.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2048.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2049.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2050.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2051.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2052.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2053.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2054.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2055.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2056.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2057.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2058.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2059.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2060.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2061.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2062.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2063.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2064.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2065.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2066.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2067.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2068.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2069.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2070.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2071.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2072.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2073.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2074.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2075.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2076.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2077.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2078.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2079.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2080.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2081.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2082.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2083.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2084.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2085.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2086.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2087.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2088.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2089.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2090.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2091.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2092.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2093.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2094.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2095.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2096.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2097.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2098.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2099.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2100.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2101.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2102.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2103.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2104.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2105.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2106.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2107.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2108.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2109.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2110.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2111.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2112.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2113.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2114.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2115.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2116.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2117.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2118.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2119.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2120.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2121.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2122.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2123.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2124.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2125.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2126.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2127.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2128.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2129.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2130.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2131.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2132.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2133.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2134.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2135.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2136.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2137.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2138.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2139.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2140.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2141.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2142.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2143.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2144.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2145.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2146.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2147.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2148.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2149.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2150.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2151.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2152.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2153.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2154.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2155.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2156.txt\n",
            "Successfully saved: /content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts/bctech2157.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install beautifulsoup4 nltk textstat\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSPcK9bu0eyn",
        "outputId": "c3efa97f-47f0-416f-a9c2-4190f995744a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: textstat in /usr/local/lib/python3.10/dist-packages (0.7.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.10/dist-packages (from textstat) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from textstat) (71.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEdli0QLjHkp",
        "outputId": "aa08234c-86d6-4933-ccb4-64dc92b27809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Download NLTK tokenizer if not already downloaded\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function to load stopwords from multiple files\n",
        "def load_stop_words(stop_words_folder):\n",
        "    stop_words = set()\n",
        "    for filename in os.listdir(stop_words_folder):\n",
        "        if filename.endswith('.txt'):\n",
        "            file_path = os.path.join(stop_words_folder, filename)\n",
        "            try:\n",
        "                with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "                    words = file.read().splitlines()\n",
        "                    stop_words.update(words)\n",
        "            except UnicodeDecodeError as e:\n",
        "                print(f\"Error decoding {filename}: {e}\")\n",
        "    return stop_words\n",
        "\n",
        "# Load positive and negative word dictionaries\n",
        "def load_word_list(filepath):\n",
        "    try:\n",
        "        with open(filepath, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "            return set(file.read().splitlines())\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding {filepath}: {e}\")\n",
        "        return set()\n",
        "\n",
        "# Load the stop words, positive, and negative word lists\n",
        "stop_words_folder = '/content/drive/MyDrive/ML/Blackcopper Test/StopWords'\n",
        "positive_words_path = '/content/drive/MyDrive/ML/Blackcopper Test/MasterDictionary/positive-words.txt'\n",
        "negative_words_path = '/content/drive/MyDrive/ML/Blackcopper Test/MasterDictionary/negative-words.txt'\n",
        "\n",
        "stop_words = load_stop_words(stop_words_folder)\n",
        "positive_words = load_word_list(positive_words_path)\n",
        "negative_words = load_word_list(negative_words_path)\n",
        "\n",
        "# Function to count syllables in a word\n",
        "def count_syllables(word):\n",
        "    word = word.lower()\n",
        "    vowels = \"aeiou\"\n",
        "    syllables = 0\n",
        "    for i, letter in enumerate(word):\n",
        "        if letter in vowels:\n",
        "            if i == 0 or word[i - 1] not in vowels:\n",
        "                syllables += 1\n",
        "    if word.endswith((\"es\", \"ed\")) and syllables > 1:\n",
        "        syllables -= 1\n",
        "    return syllables\n",
        "\n",
        "# Function to count personal pronouns\n",
        "def count_personal_pronouns(text):\n",
        "    pronoun_pattern = r'\\b(I|we|my|ours|us)\\b'\n",
        "    pronouns = re.findall(pronoun_pattern, text, re.I)\n",
        "    return len(pronouns)\n",
        "\n",
        "# Text analysis function\n",
        "def text_analysis(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = word_tokenize(text.lower())\n",
        "    filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
        "\n",
        "    positive_score = sum(1 for word in filtered_words if word in positive_words)\n",
        "    negative_score = sum(1 for word in filtered_words if word in negative_words) * -1\n",
        "    polarity_score = (positive_score - abs(negative_score)) / ((positive_score + abs(negative_score)) + 0.000001)\n",
        "    subjectivity_score = (positive_score + abs(negative_score)) / (len(filtered_words) + 0.000001)\n",
        "\n",
        "    word_count = len(filtered_words)\n",
        "    syllable_count = sum([count_syllables(word) for word in filtered_words])\n",
        "    syllables_per_word = syllable_count / word_count if word_count != 0 else 0\n",
        "    avg_word_length = sum(len(word) for word in filtered_words) / word_count if word_count != 0 else 0\n",
        "\n",
        "    # Analysis of Readability (Gunning Fog Index)\n",
        "    avg_sentence_length = word_count / len(sentences) if len(sentences) > 0 else 0\n",
        "    complex_word_count = sum(1 for word in filtered_words if count_syllables(word) > 2)\n",
        "    percentage_complex_words = (complex_word_count / word_count) * 100 if word_count != 0 else 0\n",
        "    fog_index = 0.4 * (avg_sentence_length + (complex_word_count / word_count) if word_count != 0 else 0)\n",
        "\n",
        "    # Personal pronouns count\n",
        "    personal_pronouns_count = count_personal_pronouns(text)\n",
        "\n",
        "    # Calculate average words per sentence\n",
        "    avg_words_per_sentence = word_count / len(sentences) if len(sentences) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'Positive Score': positive_score,\n",
        "        'Negative Score': abs(negative_score),\n",
        "        'Polarity Score': polarity_score,\n",
        "        'Subjectivity Score': subjectivity_score,\n",
        "        'Word Count': word_count,\n",
        "        'Syllables per Word': syllables_per_word,\n",
        "        'Avg Word Length': avg_word_length,\n",
        "        'Complex Word Count': complex_word_count,\n",
        "        'Percentage of Complex Words': percentage_complex_words,\n",
        "        'Fog Index': fog_index,\n",
        "        'Avg Sentence Length': avg_sentence_length,\n",
        "        'Avg Words Per Sentence': avg_words_per_sentence,\n",
        "        'Personal Pronouns': personal_pronouns_count\n",
        "    }\n",
        "\n",
        "# Main function to update the existing Excel with analysis results\n",
        "def update_existing_excel(existing_excel_path, folder_path, output_file):\n",
        "    # Load existing Excel file\n",
        "    df = pd.read_excel(existing_excel_path)\n",
        "\n",
        "    # Iterate through the rows of the Excel to perform text analysis for each ID\n",
        "    analysis_data = []\n",
        "    for index, row in df.iterrows():\n",
        "        file_id = row['URL_ID']  # Assuming 'ID' column in the Excel file matches .txt file names\n",
        "        file_path = os.path.join(folder_path, f'{file_id}.txt')\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                text = file.read()\n",
        "\n",
        "                # Perform text analysis\n",
        "                analysis_results = text_analysis(text)\n",
        "\n",
        "                # Append results to a list\n",
        "                analysis_data.append({**row.to_dict(), **analysis_results})\n",
        "        else:\n",
        "            print(f\"File for ID {file_id} not found.\")\n",
        "\n",
        "    # Create a new DataFrame with the updated results\n",
        "    updated_df = pd.DataFrame(analysis_data)\n",
        "\n",
        "    # Save the updated DataFrame back to a new Excel file\n",
        "    updated_df.to_excel(output_file, index=False)\n",
        "\n",
        "# Paths\n",
        "existing_excel_path = '/content/drive/MyDrive/ML/Blackcopper Test/Output Data Structure.xlsx'  # Existing Excel file with ID-URL mappings\n",
        "folder_path = '/content/drive/MyDrive/ML/Blackcopper Test/Extracted_Texts'  # Folder with .txt files\n",
        "output_file = '/content/drive/MyDrive/ML/Blackcopper Test/Updated_Text_Analysis_Results.xlsx'\n",
        "\n",
        "# Run the analysis and update the Excel file\n",
        "update_existing_excel(existing_excel_path, folder_path, output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK_gFkXOjJl6",
        "outputId": "c43cbc5e-85d9-43bd-c92d-d80d562a56f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jQTqL9tEnALl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}